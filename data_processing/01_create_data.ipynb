{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cofig = configparser.RawConfigParser()\n",
    "cofig.read('config.ini')\n",
    "url = cofig['scrap_url']['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_browser(path):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(path)\n",
    "\n",
    "        time.sleep(10) # Wait for page to load\n",
    "        \n",
    "        driver.find_element(By.XPATH, '//button[text() =\"Ask Me Later\"]').click()\n",
    "\n",
    "        print('Driver created successfully')\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "def collect_data(driver, scroll_value=1100):\n",
    "    try:\n",
    "        product_data = []  # Store results\n",
    "\n",
    "        # Scroll multiple times to load more images\n",
    "        for _ in tqdm(range(scroll_value)):  \n",
    "            driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(4)  # Allow time for new images to load\n",
    "\n",
    "            # Find all product links\n",
    "            product_cards = driver.find_elements(By.CLASS_NAME, \"ProductModule__aTag\")\n",
    "\n",
    "            for product in product_cards:\n",
    "                # Extract the product name from the title attribute\n",
    "                product_name = product.get_attribute(\"title\")\n",
    "\n",
    "                try:\n",
    "                    # Find the image element inside the product card\n",
    "                    img_tag = product.find_element(By.TAG_NAME, \"img\")\n",
    "                    img_url = img_tag.get_attribute(\"src\")\n",
    "\n",
    "                    # TataCliq sometimes provides relative URLs; make them absolute\n",
    "                    if img_url.startswith(\"//\"):\n",
    "                        img_url = \"https:\" + img_url\n",
    "                except:\n",
    "                    img_url = \"No Image Found\"\n",
    "\n",
    "                # Store the extracted details\n",
    "                product_data.append((product_name, img_url))\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "        return product_data\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [1:37:33<00:00,  5.32s/it]\n"
     ]
    }
   ],
   "source": [
    "driver = open_browser(path=url)\n",
    "product_data = collect_data(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56522/561394997.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_data['product_id'] = image_data['image_url'].apply(lambda x: re.findall(pattern, x)[0])\n"
     ]
    }
   ],
   "source": [
    "scrap_data = pd.DataFrame(product_data, columns=['product_name', 'image_url'])\n",
    "image_data = scrap_data[~(scrap_data['image_url']=='No Image Found')]\n",
    "\n",
    "pattern = r'MP\\d+'\n",
    "image_data['product_id'] = image_data['image_url'].apply(lambda x: re.findall(pattern, x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_data.to_csv('product_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
